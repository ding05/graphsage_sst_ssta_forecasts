import torch
import torch.nn as nn
from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GatedGraphConv, RGCNConv

# Set up the multi-graph GCN, using and modifying the code generated by ChatGPT-3.5/4.

class MultiGraphGCN(torch.nn.Module):
    def __init__(self, in_channels, hid_channels, out_channels, num_graphs):
        super(MultiGraphGCN, self).__init__()
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(GCNConv(in_channels, hid_channels), GCNConv(hid_channels, out_channels)) for _ in range(num_graphs)])
        #self.convs = torch.nn.ModuleList([torch.nn.Sequential(GCNConv(in_channels, hid_channels), GCNConv(hid_channels, hid_channels), GCNConv(hid_channels, hid_channels), GCNConv(hid_channels, out_channels)) for _ in range(num_graphs)])
        #self.double()
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index)
                #x = torch.tanh(x) # tanh() and sigmoid() suit y in [-1, 1].
                #x = F.relu(x) # relu() ant its variant suit y in a larger range.
                x = torch.tanh(x)
            x_list.append(x)
        x_concat = torch.cat(x_list, dim=0)
        return x_concat

class MultiGraphGAT(nn.Module):
    def __init__(self, in_channels, hid_channels, out_channels, num_heads, num_graphs):
        super(MultiGraphGAT, self).__init__()
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(GATConv(in_channels, hid_channels, num_heads), GATConv(hid_channels * num_heads, out_channels, 1)) for _ in range(num_graphs)])
        #self.convs = torch.nn.ModuleList([torch.nn.Sequential(GATConv(in_channels, hid_channels, num_heads), GATConv(hid_channels * num_heads, hid_channels, num_heads), GATConv(hid_channels * num_heads, out_channels, 1)) for _ in range(num_graphs)])
        #self.double()
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index)
                x = torch.tanh(x)
            x_list.append(x)
        x_concat = torch.cat(x_list, dim=0)
        return x_concat

class MultiGraphSage(torch.nn.Module):
    def __init__(self, in_channels, hid_channels, out_channels, num_graphs, aggr='mean'):
        super(MultiGraphSage, self).__init__()
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(SAGEConv(in_channels, hid_channels, aggr=aggr), SAGEConv(hid_channels, out_channels, aggr=aggr)) for _ in range(num_graphs)])
        #self.double()
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index)
                x = torch.tanh(x)
            x_list.append(x)
        x_concat = torch.cat(x_list, dim=0)
        return x_concat

# If outputing one value
class MultiGraphSage_G(torch.nn.Module):
    def __init__(self, in_channels, hid_channels, hid_channels_2, out_channels, num_graphs, aggr='mean'):
        super(MultiGraphSage_G, self).__init__()
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(SAGEConv(in_channels, hid_channels, aggr=aggr), SAGEConv(hid_channels, out_channels, aggr=aggr)) for _ in range(num_graphs)])
        #self.final_conv = torch.nn.Sequential(SAGEConv(out_channels * num_graphs, hid_channels, aggr=aggr), SAGEConv(hid_channels, 1, aggr=aggr))
        self.final_linear = torch.nn.Sequential(torch.nn.Linear(out_channels, hid_channels_2), torch.nn.Linear(hid_channels_2, 1))
        #self.final_linear = nn.Linear(out_channels, 1)
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index)
                x = torch.tanh(x)
            x_list.append(x)
        x_concat = torch.cat(x_list, dim=0)
        x_final = self.final_linear(x_concat)
        return x_final.mean()

# If adding an LSTM layer
class MultiGraphSage_LSTM(torch.nn.Module):
    def __init__(self, in_channels, hid_channels, out_channels, num_graphs, aggr='mean'):
        super(MultiGraphSage_LSTM, self).__init__()
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(SAGEConv(in_channels, hid_channels, aggr=aggr), SAGEConv(hid_channels, out_channels, aggr=aggr)) for _ in range(num_graphs)])
        #self.double()
        self.lstm = nn.LSTM(input_size=out_channels, hidden_size=out_channels, batch_first=True)
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index)
                x = torch.tanh(x)
            x_list.append(x)
        x_seq = torch.stack(x_list)
        lstm_out, _ = self.lstm(x_seq)
        return lstm_out

class MultiGraphGGCN(torch.nn.Module):
    def __init__(self, in_channels, hid_channels, out_channels, num_graphs):
        super(MultiGraphGGCN, self).__init__()
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(GatedGraphConv(in_channels, hid_channels), GatedGraphConv(hid_channels, out_channels)) for _ in range(num_graphs)])
        self.fc = nn.Linear(hid_channels, out_channels)
        #self.double()
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index)
                x = torch.tanh(x)
            x_list.append(x)
        x_concat = torch.cat(x_list, dim=0)
        out = self.fc(x_concat)
        return out

# If directed graphs
class MultiGraphRGCN(torch.nn.Module):
    def __init__(self, in_channels, hid_channels, out_channels, num_relations, num_bases):
        super(MultiGraphRGCN, self).__init__()
        #self.convs = torch.nn.ModuleList([torch.nn.Sequential(GCNConv(in_channels, hid_channels, num_relations, num_bases), GCNConv(hid_channels, hid_channels, num_relations, num_bases), GCNConv(hid_channels, out_channels, num_relations, num_bases))])
        self.convs = torch.nn.ModuleList([torch.nn.Sequential(GCNConv(in_channels, hid_channels, num_relations, num_bases), GCNConv(hid_channels, hid_channels, num_relations, num_bases), GCNConv(hid_channels, hid_channels, num_relations, num_bases), GCNConv(hid_channels, out_channels, num_relations, num_bases))])
        #self.double()
    def forward(self, data_list):
        x_list = []
        for i, data in enumerate(data_list):
            x = data.x
            for j, layer in enumerate(self.convs[i]):
                x = layer(x, data.edge_index, data.edge_attr)
                x = torch.tanh(x)
            x_list.append(x)
        x_concat = torch.cat(x_list, dim=0)
        return x_concat